---
title: "HDT2"
author: "Elean Rivas, Javier Alvarez"
date: "2023-02-16"
output: pdf_document
---

###Universidad del Valle de Guatemala
###Mineria de datos
###Elean Rivas - 19062
###Javier Alarez - 18051
###Elean Rivas - 19062


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
peliculas <- read.csv("movies.csv")
```
##1. Haga el preprocesamiento del dataset, explique qué variables no aportan información a la generación de grupos y por qué. 
    Describa con qué variables calculará los grupos. 
```{r}
variables <- c("original_title", "originalLanguage", "homePage", "video", "actorsCharacter")
DF.variable <- data.frame(variables)
print(DF.variable)

```
Estas variables son (en nuestra opinion) variables que no ayudan con la generacion de los grupos ya que tienen caracteristicas propias que no se relacionan con las demas y/o contienen informacion no usable.

##2. Analice la tendencia al agrupamiento usando el estadístico de Hopkings y la VAT (Visual Assessment of cluster Tendency). Discuta sus resultados e impresiones. 

```{r}
library(hopkins)
peliculas <- peliculas[complete.cases(peliculas),]
popularity <- peliculas[, 'popularity']
budget <- peliculas[, 'budget']
revenue <- peliculas[,'revenue']
runtime <- peliculas[,'runtime']
voteCount <- peliculas[,'voteCount']
normd <- data.frame(popularity,budget,revenue,runtime, voteCount )
clustering <- scale(normd)

hopkins(clustering)

dataDist <- dist(clustering)
```

```{r, echo=FALSE, results='hide',fig.keep='all'} 
library(ggplot2)
library(factoextra) 
knitr::opts_chunk$set(fig.width=12, fig.height=8) 
fviz_dist(dataDist, show_labels = F)

```

Podemos observar que el valor que retorna la funcion de hopkins esta bastante alejado de 0.5, por lo podemos decir que los datos recopilados no son aleatorios. 


##3. Determine cuál es el número de grupos a formar más adecuado para los datos que está trabajando. 
    Haga una gráfica de codo y explique la razón de la elección de la cantidad de clústeres con la que trabajará. 
  
```{r}
wss = 0
for (i in 1:10)
  wss[i] <- sum(kmeans(clustering[,1:5], centers=i)$withinss)
plot(1:10, wss, type="b", xlab="Numero de Clusters",  ylab="WSS")
```

Basado en el resultado, podemos decir que el número de clusters óptimo para analizar los datos es 6.


##4. Utilice  los  algoritmos  k-medias  y  clustering  jerárquico  para  agrupar.  Compare  los  resultados generados por cada uno. 

K-medias:
```{r , echo=FALSE, results='hide',fig.keep='all'}
library(fpc)
library(factoextra)
library(ggplot2)
library(cluster)

k<-kmeans(clustering,3,iter.max =100)
peliculas$grupo<-k$cluster
plotcluster(clustering,k$cluster) 
fviz_cluster(k, data = clustering,geom = "point", ellipse.type = "norm")
SiluetaK<-silhouette(k$cluster,dist(clustering))
mean(SiluetaK[,3]) 
Kmean<-mean(SiluetaK[,3]) 
plot(SiluetaK, cex.names=.4, col=1:3, border=NA)
```

El resultado es muy cercano a 1, el cual es un resultado deseable.

clustering  jerárquico 

```{r, echo=FALSE, results='hide',fig.keep='all'}
library(cluster)
Matrix<- dist(clustering)
hc<-hclust(dataDist, method = "ward.D2")
plot(hc, cex=0.5, axes=FALSE)
rect.hclust(hc,k=3)

groups<-cutree(hc,k=3)
peliculas$gruposHC<-groups

silhc<-silhouette(groups,dataDist)
mean(silhc[,3]) 
Jerarquico<-mean(silhc[,3])

plot(silhc, cex.names=.4, col=1:3, border = NA)
```

Similar al resultado anterior, obtuvimos un resultado deseable, cercano a 1

##5 Determine la calidad del agrupamiento hecho por cada algoritmo con el método de la silueta. Discuta los resultados. 


K-mean
En el caso del Kmean, por método de la siluete obtuvimos que la primera agrupación se comporta de manera coherente, en el caso de la 2da y 3ra muestra vemos unos valores atipicos, pero con un coeficiente adecuado cercano a 1


Cluster jerarquico



Los clusters jerarquicos mostraron una consistencia en la data más que aceptable sin mostrar valores atípicos muy altos o incongruentes

Mezcla de gaussiano

El caso de la mezcla gaussiana fue la que provoco mayor disparidad en los datos, pues la cantidad de información atípica fue la más alta, esto puede observarse en los dos primeros clusters, aunque el tercero muestra una agrupación con gran coherencia casi acercandose al cero.



##6 Interprete  los  grupos  basado  en  el  conocimiento  que  tiene  de  los  datos.  Recuerde  investigar  las medidas de tendencia central de las variables             continuas y las tablas de frecuencia de las variables categóricas pertenecientes a cada grupo. Identifique hallazgos interesantes debido a las 
    agrupaciones y describa para qué le podría servir. 
    
```{r}
mean(x = normd$popularity, na.rm = TRUE)
```


```{r}
mean(x = normd$budget, na.rm = TRUE)
```


```{r }
mean(x = normd$revenue, na.rm = TRUE)
```

```{r}
mean(x = normd$runtime, na.rm = TRUE)
```


```{r}
round(mean(x = normd$voteCount, na.rm = TRUE))
```


```{r}
tab <- table(normd$popularity)
head(sort(tab, decreasing = TRUE), n = 15)
```


```{r}
tab <- table(normd$budget)
head(sort(tab, decreasing = TRUE), n = 15)
```


```{r}
tabla <- table(normd$revenue)
head(sort(tabla, decreasing = TRUE), n = 15)
```


```{r}
tabla <- table(normd$runtime)
head(sort(tabla, decreasing = TRUE), n = 15)
```


```{r}
tabla <- table(normd$voteCount)
head(sort(tabla, decreasing = TRUE), n = 15)
```
